# Copyright 2017 The TensorFlow Authors All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Matches two images using their DELF features.

The matching is done using feature-based nearest-neighbor search, followed by
geometric verification using RANSAC.

The DELF features can be extracted using the extract_features.py script.
"""

import sys

sys.path.append("/home/kimmy/models/research")  # to import `object_detection`
import os

import numpy as np
from tqdm import tqdm
from joblib import Parallel, delayed
from scipy.spatial import cKDTree
from glob import glob
from skimage.feature import plot_matches
from skimage.measure import ransac
from skimage.transform import AffineTransform

from delf import feature_io

_DISTANCE_THRESHOLD = 0.8
_MAXIMUM_MATCH = 20


def get_matched_landmark(query_feat_path, pred_cls, cls_root, data_root):
    try:
        locations_1, _, descriptors_1, _, _ = feature_io.ReadFromFile(query_feat_path)
        num_features_1 = locations_1.shape[0]
        # print("Loaded query image's %d features" % num_features_1)
    except:
        return None

    img_with_same_cls_file = glob(os.path.join(cls_root, f"cls_{str(pred_cls).zfill(6)}_*.txt"))
    with open(img_with_same_cls_file[0], 'r') as f:
        lines = f.readlines()
    img_paths = [os.path.join(data_root, l.strip()) for l in lines]

    # Find nearest-neighbor matches using a KD tree.
    d1_tree = cKDTree(descriptors_1)
    all_inliers = []
    for img_path in img_paths[:min(_MAXIMUM_MATCH, len(img_paths))]:
        cls_feat_path = img_path.replace("dataset", "dataset/delf")[:-4] + ".delf"
        cls_feat_path = os.path.join()
        try:
            locations_2, _, descriptors_2, _, _ = feature_io.ReadFromFile(cls_feat_path)
        except:
            continue
        num_features_2 = locations_2.shape[0]
        # print("Loaded the same class image's %d features" % num_features_2)
        _, indices = d1_tree.query(descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)
        # Select feature locations for putative matches.
        locations_2_to_use = np.array([
            locations_2[i,]
            for i in range(num_features_2)
            if indices[i] != num_features_1
        ])
        locations_1_to_use = np.array([
            locations_1[indices[i],]
            for i in range(num_features_2)
            if indices[i] != num_features_1
        ])

        # Perform geometric verification using RANSAC.
        try:
            _, inliers = ransac(
                    (locations_1_to_use, locations_2_to_use),
                    AffineTransform,
                    min_samples=3,
                    residual_threshold=20,
                    max_trials=1000)
            num_inliers = sum(inliers)
            all_inliers.append(num_inliers)
        except:
            continue

    return all_inliers


def delf_submission(submission_df, delf_root, cls_root, data_root):
    """
    Args:
        - submission_df: the dataframe of the submission csv file
        - delf_root: the path to all extracted training delf
        - cls_root: the root to the txt file contains image paths have the class.
                    It can be generated by `group_landmarkid_by_class` in `utils.util`
        - data_root: the path to the dataset
    :return:
    """
    df = submission_df
    for i, (id, score) in tqdm(df.iterrows(), total=len(df)):
        pred, conf = score.split()
        pred, conf = int(pred), float(conf)
        # skip confident ones
        if conf < 0.5:
            query_feat_path = os.path.join(delf_root, f"{id}.delf")
            all_inliers = get_matched_landmark(query_feat_path, pred, cls_root, data_root)
            if all_inliers is None:  # didn't have corresponding test delf feature
                continue
            if all_inliers and np.mean(all_inliers) < 5:
                print(f"\nNo landmark in {query_feat_path.split('/')[-1][:-5]}")
                df.loc[df['id'] == id, 'landmarks'] = ""
    return df


def delf_worker(filtered, id, score, delf_root, cls_root, data_root, conf_threshold):
    pred, conf = score.split()
    pred, conf = int(pred), float(conf)
    # skip confident ones
    if conf < conf_threshold:
        query_feat_path = os.path.join(delf_root, f"{id}.delf")
        all_inliers = get_matched_landmark(query_feat_path, pred, cls_root, data_root)
        if all_inliers is None:  # didn't have corresponding test delf feature
            return
        if all_inliers and np.mean(all_inliers) < 5:
            print(f"No landmark in {query_feat_path.split('/')[-1][:-5]}")
            filtered.append(id)


def delf_master(df, delf_root, cls_root, conf_threshold=0.6):
    """
    Args:
        - submission_df: the dataframe of the submission csv file
        - delf_root: the path to all extracted training delf
        - cls_root: the root to the txt file contains image paths have the class.
                    It can be generated by `group_landmarkid_by_class` in `utils.util`
    """
    filtered = []
    Parallel(n_jobs=-1, verbose=1)(
            delayed(delf_worker)(filtered, id, score, delf_root, cls_root, conf_threshold)
            for i, (id, score) in tqdm(list(df.iterrows()), total=len(df)))
    for id in filtered:
        df.loc[df['id'] == id, 'landmarks'] = ""


def my_test_matching():
    query_feat_path = "/home/kimmy/dataset/test_delf/01c11582ad34f77d.delf"
    all_inliers = get_matched_landmark(query_feat_path, 36586, "/home/kimmy/dataset/cls", "/home/kimmy/dataset")
    if all_inliers and np.mean(all_inliers) < 5:
        print(f"No landmark in {query_feat_path.split()[-1][:-5]}")
